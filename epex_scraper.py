import datetime
import os
import pandas as pd
import time
import undetected_chromedriver as uc
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup


def fetch_epex_prices():
    trading_date = datetime.date.today().strftime("%Y-%m-%d")
    delivery_date = (datetime.date.today() + datetime.timedelta(days=1)).strftime("%Y-%m-%d")

    os.makedirs("archives/html", exist_ok=True)
    os.makedirs("archives/csv", exist_ok=True)

    # ‚öôÔ∏è Options Chrome
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument(
        "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
    )

    print("üåê Lancement de Chrome via undetected-chromedriver (version 140)...")
    try:
        driver = uc.Chrome(version_main=140, options=options)
    except Exception as e:
        print(f"‚ùå Erreur au lancement de Chrome : {e}")
        return

    driver.get("https://www.epexspot.com/en/market-results")
    wait = WebDriverWait(driver, 25)

    # 1Ô∏è‚É£ Accepter le disclaimer s‚Äôil appara√Æt
    try:
        button = wait.until(EC.element_to_be_clickable((By.ID, "edit-acceptationbutton")))
        button.click()
        print("‚úÖ Disclaimer accept√©.")
    except Exception:
        print("‚ö†Ô∏è Aucun bouton d‚Äôacceptation d√©tect√© (peut-√™tre d√©j√† valid√©).")

    # 2Ô∏è‚É£ Attendre que les filtres soient disponibles
    try:
        wait.until(EC.presence_of_element_located((By.ID, "md_filters_wrapper")))
        print("‚úÖ Bloc de filtres d√©tect√©.")
    except Exception:
        print("‚ùå Bloc de filtres introuvable, tentative de rechargement...")
        driver.refresh()
        time.sleep(8)

    # 3Ô∏è‚É£ Scroll pour d√©clencher les scripts JS
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight / 2);")
    time.sleep(4)

    # 4Ô∏è‚É£ Clic sur ‚ÄúSee Results‚Äù pour charger les prix
    try:
        see_button = wait.until(
            EC.element_to_be_clickable(
                (By.CSS_SELECTOR, ".btn.btn-primary-outline.btn-full.btn-see-results")
            )
        )
        driver.execute_script("arguments[0].click();", see_button)
        print("üîé Recherche des r√©sultats lanc√©e.")
    except Exception as e:
        print(f"‚ùå Impossible de cliquer sur See Results : {e}")
        driver.quit()
        return

    # 5Ô∏è‚É£ Attendre que le tableau apparaisse
    try:
        wait.until(EC.presence_of_element_located((By.TAG_NAME, "table")))
        print("‚úÖ Tableau d√©tect√©.")
    except Exception:
        print("‚ö†Ô∏è Tableau non d√©tect√© apr√®s 20 secondes.")
        html_path = f"archives/html/epex_FR_{delivery_date}_empty.html"
        with open(html_path, "w", encoding="utf-8") as f:
            f.write(driver.page_source)
        print(f"üìÑ Page enregistr√©e pour diagnostic : {html_path}")
        driver.quit()
        return

    # 6Ô∏è‚É£ Sauvegarder le HTML
    html = driver.page_source
    html_path = f"archives/html/epex_FR_{delivery_date}.html"
    with open(html_path, "w", encoding="utf-8") as f:
        f.write(html)
    print(f"üìÑ Page enregistr√©e : {html_path}")

    # 7Ô∏è‚É£ Parser le tableau
    soup = BeautifulSoup(html, "html.parser")
    table = soup.find("table")
    rows = []
    for tr in table.find_all("tr"):
        cells = [td.get_text(strip=True) for td in tr.find_all(["td", "th"])]
        if cells:
            rows.append(cells)

    if len(rows) < 2:
        print("‚ö†Ô∏è Aucun contenu exploitable trouv√© dans le tableau.")
    else:
        df = pd.DataFrame(rows[1:], columns=rows[0])
        csv_path = f"archives/csv/epex_FR_{delivery_date}.csv"
        df.to_csv(csv_path, index=False, encoding="utf-8-sig")
        print(f"üìä Fichier CSV enregistr√© : {csv_path} ({len(df)} lignes)")

    driver.quit()


if __name__ == "__main__":
    fetch_epex_prices()



'''
import datetime
import os
import requests
import sys  # pour signaler l'√©chec au workflow

def fetch_epex_prices():
    trading_date = datetime.date.today().strftime("%Y-%m-%d")
    delivery_date = (datetime.date.today() + datetime.timedelta(days=1)).strftime("%Y-%m-%d")

    os.makedirs("archives/html", exist_ok=True)
    os.makedirs("archives/csv", exist_ok=True)

    url = (
    f"https://www.epexspot.com/en/market-results?"
    f"market_area=XX&auction=MRC"   # XX n'existe pas
    f"&trading_date={trading_date}"
    f"&delivery_date={delivery_date}"
    f"&modality=Auction&sub_modality=DayAhead&data_mode=table&product=60"
    )


    html_path = f"archives/html/epex_FR_{delivery_date}.html"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "fr-FR,fr;q=0.9,en;q=0.8",
        "Connection": "keep-alive",
        "Referer": "https://www.epexspot.com/en/market-results",
        "Upgrade-Insecure-Requests": "1",
    }

    try:
        print("üì° Requ√™te principale (requests)...")
        response = requests.get(url, headers=headers, timeout=30)
        status = response.status_code
        print(f"üì∂ Statut HTTP : {status}")

        if status == 200 and "Forbidden" not in response.text:
            print("‚úÖ Page HTML t√©l√©charg√©e avec succ√®s.")
            with open(html_path, "w", encoding="utf-8") as f:
                f.write(response.text)
            print(f"üìÑ Page HTML archiv√©e : {html_path}")
        else:
            print("‚ùå Acc√®s refus√© ou page vide.")
            sys.exit(1)  # <-- signal d'√©chec imm√©diat

    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration : {e}")
        sys.exit(1)  # <-- signal d'√©chec imm√©diat

if __name__ == "__main__":
    fetch_epex_prices()


import datetime
import os
import requests

def fetch_epex_prices():
    # üìÖ Dates
    trading_date = datetime.date.today().strftime("%Y-%m-%d")
    delivery_date = (datetime.date.today() + datetime.timedelta(days=1)).strftime("%Y-%m-%d")

    # üìÇ Dossiers
    os.makedirs("archives/html", exist_ok=True)
    os.makedirs("archives/csv", exist_ok=True)

    # üåê URL cible
    url = (
        f"https://www.epexspot.com/en/market-results?"
        f"market_area=FR&auction=MRC"
        f"&trading_date={trading_date}"
        f"&delivery_date={delivery_date}"
        f"&modality=Auction&sub_modality=DayAhead&data_mode=table&product=60"
    )

    print(f"üîó URL utilis√©e : {url}")

    # üß† Headers complets (simulation navigateur Chrome)
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/128.0.0.0 Safari/537.36"
        ),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "fr-FR,fr;q=0.9,en;q=0.8",
        "Connection": "keep-alive",
        "Referer": "https://www.epexspot.com/en/market-results",
        "Upgrade-Insecure-Requests": "1",
    }

    html_path = f"archives/html/epex_FR_{delivery_date}.html"

    try:
        print("üì° Requ√™te principale (requests)...")
        response = requests.get(url, headers=headers, timeout=30)
        status = response.status_code
        print(f"üì∂ Statut HTTP : {status}")

        # ‚ö†Ô∏è V√©rification simple du contenu
        if status == 200 and "Forbidden" not in response.text:
            print("‚úÖ Page HTML t√©l√©charg√©e avec succ√®s.")
            with open(html_path, "w", encoding="utf-8") as f:
                f.write(response.text)
            print(f"üìÑ Page HTML archiv√©e : {html_path}")
        else:
            print("‚ùå Acc√®s refus√© ou page vide, page sauvegard√©e pour diagnostic.")
            with open(html_path, "w", encoding="utf-8") as f:
                f.write(response.text)
            print(f"üìÑ Page archiv√©e pour analyse : {html_path}")

    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration : {e}")

if __name__ == "__main__":
    fetch_epex_prices()



import datetime
import requests
from bs4 import BeautifulSoup
import pandas as pd
import os

def fetch_epex_prices():
    # üìÖ Aujourd‚Äôhui = jour d‚Äôex√©cution ; Demain = livraison
    trading_date = datetime.date.today().strftime("%Y-%m-%d")
    delivery_date = (datetime.date.today() + datetime.timedelta(days=1)).strftime("%Y-%m-%d")

    # üìÇ Cr√©er les dossiers d‚Äôarchives
    os.makedirs("archives/html", exist_ok=True)
    os.makedirs("archives/csv", exist_ok=True)

    # üåê URL cible
    url = (
        f"https://www.epexspot.com/en/market-results?"
        f"market_area=FR&auction=MRC"
        f"&trading_date={trading_date}"
        f"&delivery_date={delivery_date}"
        f"&modality=Auction&sub_modality=DayAhead&data_mode=table&product=60"
    )
    print(f"üîó URL utilis√©e : {url}")

    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)

    # üíæ Archive HTML
    html_path = f"archives/html/epex_FR_{delivery_date}.html"
    with open(html_path, "w", encoding="utf-8") as f:
        f.write(response.text)
    print(f"üìÑ Page HTML archiv√©e : {html_path}")


if __name__ == "__main__":
    fetch_epex_prices()
'''
