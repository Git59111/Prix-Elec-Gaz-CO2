import datetime
import os
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import time

def fetch_epex_prices():
    trading_date = datetime.date.today().strftime("%Y-%m-%d")
    delivery_date = (datetime.date.today() + datetime.timedelta(days=1)).strftime("%Y-%m-%d")

    os.makedirs("archives/html", exist_ok=True)
    os.makedirs("archives/csv", exist_ok=True)

    # ‚öôÔ∏è Chrome headless
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    print("üåê Lancement de Chrome (headless)...")
    driver = webdriver.Chrome(options=options)
    driver.get("https://www.epexspot.com/en/market-results")

    # 1Ô∏è‚É£ Accepter le disclaimer
    try:
        button = driver.find_element("id", "edit-acceptationbutton")
        button.click()
        print("‚úÖ Disclaimer accept√©.")
    except Exception:
        print("‚ö†Ô∏è Bouton d‚Äôacceptation introuvable, peut-√™tre d√©j√† valid√©.")

    time.sleep(5)  # attendre le chargement dynamique

    # 2Ô∏è‚É£ Filtrer sur la France et le Day-Ahead
    driver.execute_script(
        "document.querySelector('input#edit-filters-market-area').value = 'FR';"
        "document.querySelector('input#edit-filters-delivery-date').value = arguments[0];"
        "document.querySelector('.btn.btn-primary-outline.btn-full.btn-see-results').click();",
        delivery_date,
    )

    time.sleep(8)  # attendre le tableau

    html = driver.page_source
    html_path = f"archives/html/epex_FR_{delivery_date}.html"
    with open(html_path, "w", encoding="utf-8") as f:
        f.write(html)
    print(f"üìÑ Page enregistr√©e : {html_path}")

    # 3Ô∏è‚É£ Parser avec BeautifulSoup
    soup = BeautifulSoup(html, "html.parser")
    table = soup.find("table")
    if not table:
        print("‚ùå Tableau introuvable (JS non charg√© ?)")
        driver.quit()
        return

    rows = []
    for tr in table.find_all("tr"):
        cells = [td.get_text(strip=True) for td in tr.find_all(["td", "th"])]
        if cells:
            rows.append(cells)

    df = pd.DataFrame(rows[1:], columns=rows[0])
    csv_path = f"archives/csv/epex_FR_{delivery_date}.csv"
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")
    print(f"üìä CSV enregistr√© : {csv_path}")

    driver.quit()

if __name__ == "__main__":
    fetch_epex_prices()



'''
import datetime
import os
import requests
import sys  # pour signaler l'√©chec au workflow

def fetch_epex_prices():
    trading_date = datetime.date.today().strftime("%Y-%m-%d")
    delivery_date = (datetime.date.today() + datetime.timedelta(days=1)).strftime("%Y-%m-%d")

    os.makedirs("archives/html", exist_ok=True)
    os.makedirs("archives/csv", exist_ok=True)

    url = (
    f"https://www.epexspot.com/en/market-results?"
    f"market_area=XX&auction=MRC"   # XX n'existe pas
    f"&trading_date={trading_date}"
    f"&delivery_date={delivery_date}"
    f"&modality=Auction&sub_modality=DayAhead&data_mode=table&product=60"
    )


    html_path = f"archives/html/epex_FR_{delivery_date}.html"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "fr-FR,fr;q=0.9,en;q=0.8",
        "Connection": "keep-alive",
        "Referer": "https://www.epexspot.com/en/market-results",
        "Upgrade-Insecure-Requests": "1",
    }

    try:
        print("üì° Requ√™te principale (requests)...")
        response = requests.get(url, headers=headers, timeout=30)
        status = response.status_code
        print(f"üì∂ Statut HTTP : {status}")

        if status == 200 and "Forbidden" not in response.text:
            print("‚úÖ Page HTML t√©l√©charg√©e avec succ√®s.")
            with open(html_path, "w", encoding="utf-8") as f:
                f.write(response.text)
            print(f"üìÑ Page HTML archiv√©e : {html_path}")
        else:
            print("‚ùå Acc√®s refus√© ou page vide.")
            sys.exit(1)  # <-- signal d'√©chec imm√©diat

    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration : {e}")
        sys.exit(1)  # <-- signal d'√©chec imm√©diat

if __name__ == "__main__":
    fetch_epex_prices()


import datetime
import os
import requests

def fetch_epex_prices():
    # üìÖ Dates
    trading_date = datetime.date.today().strftime("%Y-%m-%d")
    delivery_date = (datetime.date.today() + datetime.timedelta(days=1)).strftime("%Y-%m-%d")

    # üìÇ Dossiers
    os.makedirs("archives/html", exist_ok=True)
    os.makedirs("archives/csv", exist_ok=True)

    # üåê URL cible
    url = (
        f"https://www.epexspot.com/en/market-results?"
        f"market_area=FR&auction=MRC"
        f"&trading_date={trading_date}"
        f"&delivery_date={delivery_date}"
        f"&modality=Auction&sub_modality=DayAhead&data_mode=table&product=60"
    )

    print(f"üîó URL utilis√©e : {url}")

    # üß† Headers complets (simulation navigateur Chrome)
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/128.0.0.0 Safari/537.36"
        ),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "fr-FR,fr;q=0.9,en;q=0.8",
        "Connection": "keep-alive",
        "Referer": "https://www.epexspot.com/en/market-results",
        "Upgrade-Insecure-Requests": "1",
    }

    html_path = f"archives/html/epex_FR_{delivery_date}.html"

    try:
        print("üì° Requ√™te principale (requests)...")
        response = requests.get(url, headers=headers, timeout=30)
        status = response.status_code
        print(f"üì∂ Statut HTTP : {status}")

        # ‚ö†Ô∏è V√©rification simple du contenu
        if status == 200 and "Forbidden" not in response.text:
            print("‚úÖ Page HTML t√©l√©charg√©e avec succ√®s.")
            with open(html_path, "w", encoding="utf-8") as f:
                f.write(response.text)
            print(f"üìÑ Page HTML archiv√©e : {html_path}")
        else:
            print("‚ùå Acc√®s refus√© ou page vide, page sauvegard√©e pour diagnostic.")
            with open(html_path, "w", encoding="utf-8") as f:
                f.write(response.text)
            print(f"üìÑ Page archiv√©e pour analyse : {html_path}")

    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration : {e}")

if __name__ == "__main__":
    fetch_epex_prices()



import datetime
import requests
from bs4 import BeautifulSoup
import pandas as pd
import os

def fetch_epex_prices():
    # üìÖ Aujourd‚Äôhui = jour d‚Äôex√©cution ; Demain = livraison
    trading_date = datetime.date.today().strftime("%Y-%m-%d")
    delivery_date = (datetime.date.today() + datetime.timedelta(days=1)).strftime("%Y-%m-%d")

    # üìÇ Cr√©er les dossiers d‚Äôarchives
    os.makedirs("archives/html", exist_ok=True)
    os.makedirs("archives/csv", exist_ok=True)

    # üåê URL cible
    url = (
        f"https://www.epexspot.com/en/market-results?"
        f"market_area=FR&auction=MRC"
        f"&trading_date={trading_date}"
        f"&delivery_date={delivery_date}"
        f"&modality=Auction&sub_modality=DayAhead&data_mode=table&product=60"
    )
    print(f"üîó URL utilis√©e : {url}")

    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)

    # üíæ Archive HTML
    html_path = f"archives/html/epex_FR_{delivery_date}.html"
    with open(html_path, "w", encoding="utf-8") as f:
        f.write(response.text)
    print(f"üìÑ Page HTML archiv√©e : {html_path}")


if __name__ == "__main__":
    fetch_epex_prices()
'''
