name: Daily EPEX Scraper

on:
  schedule:
    - cron: "0 13 * * *"  # 15h00 Paris (UTC+2)
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ§© Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Install dependencies (including Selenium + Chrome)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install selenium beautifulsoup4 pandas
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver
          echo "âœ… Chrome et Selenium installÃ©s."

      - name: â–¶ï¸ Run EPEX + Gaz + CO2 scrapers
        run: |
          echo "ğŸ“¥ Lancement des scrapers..."
          python fetch_gaz_co2_weekend.py  # <--- NOUVEAU
          python fetch_gaz_co2_html.py
          python epex_scraper.py
          echo "ğŸ“ Contenu du dossier aprÃ¨s exÃ©cution :"
          ls -lha archives/html || echo "Pas de dossier HTML"
          ls -lha archives/csv || echo "Pas de dossier CSV"

      - name: ğŸ’¾ Commit and push archived HTML/CSV files
        run: |
          git config --global user.email "action@github.com"
          git config --global user.name "GitHub Actions"
          git pull --rebase origin main || true
          git add archives/html/*.html || echo "No electric HTML to add"
          git add archives/csv/*.csv || echo "No CSV to add"
          git add archives/html_gaz/*.html || echo "No gas HTML to add"
          git add archives/html_co2/*.html || echo "No CO2 HTML to add"
          git commit -m "ğŸ“„ Archives HTML/CSV (elec + gaz + CO2) for $(date +'%Y-%m-%d')" || echo "Nothing to commit"
          git push origin main || echo "âš ï¸ Nothing new to push"

